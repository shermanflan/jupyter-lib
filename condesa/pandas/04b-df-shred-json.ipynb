{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.io.json\n",
    "import numpy as np\n",
    "import numba\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = {\n",
    "   \"517098\": {\n",
    "      \"rec_date\": \"2019-07-08\",\n",
    "      \"doc_date\": \"06/26/2019\",\n",
    "      \"document_id\": \"517098\",\n",
    "      \"grantor\": [\n",
    "         \"HESS BAKKEN INVESTMENTS II LLC\",\n",
    "         \"2 HESS BAKKEN INVESTMENTS II LLC\",\n",
    "         \"3 HESS BAKKEN INVESTMENTS II LLC\"\n",
    "      ],\n",
    "      \"grantee\": [\n",
    "         \"PUBLIC\",\n",
    "         \"2PUBLIC\",\n",
    "         \"3PUBLIC\"\n",
    "      ],\n",
    "      \"instrument_type\": \"Affidavit\",\n",
    "      \"legal\": [\n",
    "         \"SE 9 151 95\",\n",
    "         \"SW 9 151 95\",\n",
    "         \"NE 9 151 95\"\n",
    "      ]\n",
    "   },\n",
    "   \"517099\": {\n",
    "      \"rec_date\": \"2019-07-08\",\n",
    "      \"doc_date\": \"06/26/2019\",\n",
    "      \"document_id\": \"517099\",\n",
    "      \"grantor\": [],\n",
    "      \"grantee\": [],\n",
    "      \"instrument_type\": \"Affidavit\",\n",
    "      \"legal\": [\n",
    "         \"SE 9 151 95\",\n",
    "         \"SW 9 151 95\",\n",
    "         \"NW SE 23 151 95\",\n",
    "         \"NW SW 17 151 95\"\n",
    "      ]\n",
    "   },\n",
    "   \"517101\": {\n",
    "      \"rec_date\": \"2019-07-08\",\n",
    "      \"doc_date\": \"06/26/2019\",\n",
    "      \"document_id\": \"517101\",\n",
    "      \"grantor\": [\n",
    "         \"HESS BAKKEN INVESTMENTS II LLC\"\n",
    "      ],\n",
    "      \"grantee\": [],\n",
    "      \"instrument_type\": \"Affidavit\",\n",
    "      \"legal\": [\n",
    "         \"SE 9 151 95\",\n",
    "         \"SW 9 151 95\",\n",
    "         \"NW SW 17 151 95\"\n",
    "      ]\n",
    "   },\n",
    "   \"517115\": {\n",
    "      \"rec_date\": \"2019-07-08\",\n",
    "      \"doc_date\": \"07/01/2019\",\n",
    "      \"document_id\": \"517115\",\n",
    "      \"grantor\": [],\n",
    "      \"grantee\": [\n",
    "         \"HESS BAKKEN INVESTMENTS II LLC\"          \n",
    "      ],\n",
    "      \"instrument_type\": \"Affidavit\",\n",
    "      \"legal\": [\n",
    "         \"NE SW 19 152 96\",\n",
    "         \"E NW 19 152 96\",\n",
    "         \"SW NW 19 152 96\"\n",
    "      ]\n",
    "   },\n",
    "   \"517135\": {\n",
    "      \"rec_date\": \"2019-07-08\",\n",
    "      \"doc_date\": \"07/01/2019\",\n",
    "      \"document_id\": \"517135\",\n",
    "      \"grantor\": [\n",
    "         \"BERGEN ESTATE, LILLIAN\",\n",
    "         \"BERGEM ESTATE AKA, LILLIAN M\",\n",
    "         \"THORESON, JENNIFER\"\n",
    "      ],\n",
    "      \"grantee\": [\n",
    "         \"PUBLIC\",\n",
    "         \"THORESON, JENNIFER\"\n",
    "      ],\n",
    "      \"instrument_type\": \"Affidavit\",\n",
    "      \"legal\": []\n",
    "   },\n",
    "   \"517865\": {\n",
    "      \"rec_date\": \"2019-07-31\",\n",
    "      \"doc_date\": \"03/29/2019\",\n",
    "      \"document_id\": \"517865\",\n",
    "      \"grantor\": [\n",
    "         \"DEHOYOS, KIMBERLY\",\n",
    "         \"DEHOYOS AKA, KIMBERLY A\"\n",
    "      ],\n",
    "      \"grantee\": [\n",
    "         \"WELLS FARGO BANK NA\"\n",
    "      ],\n",
    "      \"instrument_type\": \"AFFIDAVIT\",\n",
    "      \"legal\": [\n",
    "         \"WATFORD CITY THIRD ADDITION 5 2\"\n",
    "      ]\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1: Use set operations (fastest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.4 ms ± 1.81 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Create single row dataframe\n",
    "df1 = pd.DataFrame(\n",
    "            data=src.values()\n",
    "            , index=src.keys() \n",
    "        )\n",
    "# Use as join key\n",
    "df1['id'] = df1.index\n",
    "\n",
    "# Split grantor into columns\n",
    "df_grantor = pd.DataFrame(df1.grantor.values.tolist()\n",
    "                  , index=df1.index)\n",
    "df_grantor['id'] = df_grantor.index\n",
    "\n",
    "# Melt (columns to rows)\n",
    "grantor = df_grantor.melt(\n",
    "            id_vars='id'\n",
    "            , value_vars=None\n",
    "            , var_name='grantor_var'\n",
    "            , value_name='grantor_new'\n",
    "        )\n",
    "# Remove empty values\n",
    "grantor.dropna(subset=['grantor_new'], inplace=True)\n",
    "    \n",
    "# Repeat for grantee (this can be refactored into a function)\n",
    "df_grantee = pd.DataFrame(df1.grantee.values.tolist()\n",
    "                  , index=df1.index)\n",
    "df_grantee['id'] = df_grantee.index # use as join key\n",
    "grantee = df_grantee.melt(\n",
    "            id_vars='id'\n",
    "            , value_vars=None\n",
    "            , var_name='grantee_var'\n",
    "            , value_name='grantee_new'\n",
    "        )\n",
    "grantee.dropna(subset=['grantee_new'], inplace=True)\n",
    "#\n",
    "\n",
    "# Repeat for legal (this can be refactored into a function)\n",
    "df_legal = pd.DataFrame(df1.legal.values.tolist()\n",
    "                  , index=df1.index)\n",
    "df_legal['id'] = df_legal.index # use as join key\n",
    "legal = df_legal.melt(\n",
    "            id_vars='id'\n",
    "            , value_vars=None\n",
    "            , var_name='legal_var'\n",
    "            , value_name='legal_new'\n",
    "        )\n",
    "legal.dropna(subset=['legal_new'], inplace=True)\n",
    "#\n",
    "\n",
    "# Now use database style set operations\n",
    "df_join1 = pd.merge(df1, grantor, how='left', on='id')\n",
    "df_join2 = pd.merge(df_join1, grantee, how='left', on='id')\n",
    "final = pd.merge(df_join2, legal, how='left', on='id')\n",
    "final = final.loc[:, ['id', 'rec_date', 'doc_date', 'document_id'\n",
    "              , 'instrument_type', 'grantor_new', 'grantee_new'\n",
    "              , 'legal_new']]\n",
    "\n",
    "assert final.shape == (45, 8)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2: Use pandas json_normalize (fast but not that fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.3 ms ± 502 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Pull grantor records\n",
    "rec_id = \"517098\"\n",
    "grantor = pandas.io.json.json_normalize(\n",
    "        data=src[rec_id]\n",
    "        , record_path=['grantor']\n",
    "        , meta=[]\n",
    "        , record_prefix='new_grantor'\n",
    "        , meta_prefix='index'\n",
    "        , sep=\"_\"\n",
    "        , errors='ignore')\n",
    "grantor['key'] = 1\n",
    "\n",
    "# Grantee\n",
    "grantee = pandas.io.json.json_normalize(\n",
    "        data=src[rec_id]\n",
    "        , record_path=['grantee']\n",
    "        , meta=[]\n",
    "        , record_prefix='new_grantee'\n",
    "        , meta_prefix='index'\n",
    "        , sep=\"_\"\n",
    "        , errors='ignore')\n",
    "grantee['key'] = 1\n",
    "\n",
    "# Legal\n",
    "legals = pandas.io.json.json_normalize(\n",
    "        data=src[rec_id]\n",
    "        , record_path=['legal']\n",
    "        , meta=['rec_date'\n",
    "                , 'doc_date'\n",
    "                , 'document_id'\n",
    "                , 'instrument_type']\n",
    "        , record_prefix='new_legal'\n",
    "        , meta_prefix='index'\n",
    "        , sep=\"_\"\n",
    "        , errors='ignore')\n",
    "legals['key'] = 1\n",
    "\n",
    "# Take cross product\n",
    "df1 = pd.merge(legals, grantor, on='key')\n",
    "final = pd.merge(df1, grantee, on='key')\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 3: Manual shredding functions (slowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_melt(index, df, pivot):\n",
    "    \n",
    "    \"\"\"Split pivot field into columns, then melt (cols->rows).\"\"\"\n",
    "    \n",
    "    if df[pivot].values[0]:\n",
    "        for i, v in enumerate(df[pivot].values[0]):\n",
    "            df[pivot+str(i)] = v\n",
    "\n",
    "        melted = df.melt(\n",
    "                        id_vars=index\n",
    "                        , value_vars=None\n",
    "                        , var_name=pivot+'_var'\n",
    "                        , value_name=pivot+'_new'\n",
    "                    )\n",
    "    else: # empty pivot\n",
    "        melted = df\n",
    "        melted[pivot+'_new'] = None\n",
    "    \n",
    "    return melted\n",
    "\n",
    "def shred_to_pandas(rec_id, raw):\n",
    "    \"\"\"Shred grantor, grantee, and legal into unqiue rows\"\"\"\n",
    "    \n",
    "    # Create single row dataframe\n",
    "    df1 = pd.DataFrame(\n",
    "                data=raw.values()\n",
    "                , index=raw.keys() \n",
    "            ).transpose()\n",
    "\n",
    "    # Split grantor into columns, then melt. \n",
    "    index = ['rec_date', 'doc_date', 'document_id', 'instrument_type'\n",
    "            , 'grantor', 'grantee', 'legal']\n",
    "\n",
    "    grantors = split_melt(index, df1, pivot='grantor')        \n",
    "        \n",
    "    # Split grantee into columns. \n",
    "    index = ['rec_date', 'doc_date', 'document_id', 'instrument_type'\n",
    "            , 'grantor_new', 'grantee', 'legal']\n",
    "\n",
    "    grantees = split_melt(index, grantors.loc[:, index], pivot='grantee')        \n",
    "\n",
    "    # Split legals. \n",
    "    index = ['rec_date', 'doc_date', 'document_id', 'instrument_type'\n",
    "            , 'grantor_new', 'grantee_new', 'legal']\n",
    "\n",
    "    legals = split_melt(index, grantees.loc[:, index], pivot='legal')        \n",
    "\n",
    "    # Assign record ID\n",
    "    legals[\"ID\"] = rec_id\n",
    "    final = legals.loc[:, ['ID', 'rec_date', 'doc_date', 'document_id'\n",
    "                          , 'instrument_type', 'grantor_new', 'grantee_new'\n",
    "                          , 'legal_new']]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run tests for option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 ms ± 2.07 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_full = []\n",
    "\n",
    "for k, v in src.items():\n",
    "    df_tmp = shred_to_pandas(k, v)\n",
    "    df_full.append(df_tmp)\n",
    "\n",
    "df_concat = pd.concat(df_full).reindex()\n",
    "assert df_concat.shape == (45, 8)\n",
    "\n",
    "df_concat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
