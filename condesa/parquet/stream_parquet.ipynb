{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples streaming to parquet format\n",
    "- [Reference](https://arrow.apache.org/docs/python/ipc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import ijson\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from pyarrow.parquet import ParquetWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_schema = pa.schema([\n",
    "    pa.field('aha_id', pa.string()),\n",
    "    pa.field('reference_prefix', pa.string()),\n",
    "    pa.field('name', pa.string()),\n",
    "    pa.field('last_release_num', pa.int32()),\n",
    "    pa.field('last_feature_num', pa.int32()),\n",
    "    pa.field('last_idea_num', pa.int32()),\n",
    "    pa.field('position', pa.int32()),\n",
    "    pa.field('positioning_customer', pa.string()),\n",
    "    pa.field('positioning_problem', pa.string()),\n",
    "    pa.field('positioning_benefit1', pa.string()),\n",
    "    pa.field('positioning_benefit2', pa.string()),\n",
    "    pa.field('positioning_benefit3', pa.string()),\n",
    "    pa.field('product_line', pa.bool_()),\n",
    "    pa.field('product_line_type', pa.string()),\n",
    "    pa.field('capacity_planning_enabled', pa.bool_()),\n",
    "    pa.field('ideas_scoring_system_id', pa.string()),\n",
    "    pa.field('ideas_default_user_id', pa.string()),\n",
    "    pa.field('default_capacity_units', pa.int32()),\n",
    "    pa.field('default_feature_remaining_estimate', pa.bool_()),\n",
    "    pa.field('last_page_num', pa.int32()),\n",
    "    pa.field('color', pa.int32()),\n",
    "    pa.field('workflow_screen_enabled', pa.bool_()),\n",
    "    pa.field('competitor_scoring_system_id', pa.string()),\n",
    "    pa.field('initiative_workflow_id', pa.string()),\n",
    "    pa.field('strategic_imperative_workflow_id', pa.string()),\n",
    "    pa.field('estimated_time_as_work_done', pa.bool_()),\n",
    "    pa.field('last_epic_num', pa.int32()),\n",
    "    pa.field('configuration', pa.string()),\n",
    "    pa.field('workspace_type', pa.string()),\n",
    "    pa.field('created_at', pa.timestamp('ms')),\n",
    "    pa.field('updated_at', pa.timestamp('ms')),\n",
    "    pa.field('parent_id', pa.string()),\n",
    "    pa.field('scoring_system_id', pa.string()),\n",
    "    pa.field('idea_workflow_id', pa.string()),\n",
    "    pa.field('feature_workflow_id', pa.string()),\n",
    "    pa.field('release_workflow_id', pa.string()),\n",
    "])\n",
    "\n",
    "requirement_schema = pa.schema([\n",
    "    pa.field('aha_id', pa.string()),\n",
    "    pa.field('reference_num', pa.string()),\n",
    "    pa.field('created_by_user_id', pa.string()),\n",
    "    pa.field('position', pa.int32()),\n",
    "    pa.field('original_estimate', pa.float32()),\n",
    "    pa.field('remaining_estimate', pa.float32()),\n",
    "    pa.field('work_done', pa.float32()),\n",
    "    pa.field('name', pa.string()),\n",
    "    pa.field('created_at', pa.timestamp('ms')),\n",
    "    pa.field('updated_at', pa.timestamp('ms')),\n",
    "    pa.field('feature_id', pa.string()),\n",
    "    pa.field('project_id', pa.string()),\n",
    "    pa.field('workflow_status_id', pa.string()),\n",
    "    pa.field('assigned_to_user_id', pa.string()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming write\n",
    "Use a DataFrame to accumulate data set and then write to parquet in batches\n",
    "- [Reference](https://stackoverflow.com/questions/56377848/writing-stream-of-big-data-to-parquet-with-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "backup_path = f\"./data/aha-account-6240998105453674102-backup-2020-12-28-18-53.json\"\n",
    "\n",
    "with open(backup_path, 'rt', encoding='utf-8') as f:\n",
    "    parser = ijson.parse(f)\n",
    "    objects = ijson.items(f, 'records.item')\n",
    "    \n",
    "    i = 0\n",
    "    project, requirement = [], []\n",
    "    project_pq = './data/aha-project-backup-2020-12-28-18-53.parquet'\n",
    "    requirement_pq = './data/aha-requirement-backup-2020-12-28-18-53.parquet'\n",
    "\n",
    "    with ParquetWriter(project_pq, project_schema, compression='SNAPPY') as w, \\\n",
    "        ParquetWriter(requirement_pq, requirement_schema, compression='SNAPPY') as r:\n",
    "\n",
    "        for record in objects:\n",
    "            if record['class'] == 'Project':\n",
    "                project.append((\n",
    "                    record['id'],\n",
    "                    record['fields']['reference_prefix'],\n",
    "                    record['fields']['name'],\n",
    "                    record['fields']['last_release_num'],\n",
    "                    record['fields']['last_feature_num'],\n",
    "                    record['fields']['last_idea_num'],\n",
    "                    record['fields']['position'],\n",
    "                    record['fields']['positioning_customer'],\n",
    "                    record['fields']['positioning_problem'],\n",
    "                    record['fields']['positioning_benefit1'],\n",
    "                    record['fields']['positioning_benefit2'],\n",
    "                    record['fields']['positioning_benefit3'],\n",
    "                    record['fields']['product_line'],\n",
    "                    record['fields']['product_line_type'],\n",
    "                    record['fields']['capacity_planning_enabled'],\n",
    "                    str(record['fields'].get('ideas_scoring_system_id')),\n",
    "                    record['fields']['ideas_default_user_id'],\n",
    "                    record['fields']['default_capacity_units'],\n",
    "                    record['fields']['default_feature_remaining_estimate'],\n",
    "                    record['fields']['last_page_num'],\n",
    "                    record['fields']['color'],\n",
    "                    record['fields']['workflow_screen_enabled'],\n",
    "                    str(record['fields']['competitor_scoring_system_id']),\n",
    "                    str(record['fields']['initiative_workflow_id']),\n",
    "                    str(record['fields']['strategic_imperative_workflow_id']),\n",
    "                    record['fields']['estimated_time_as_work_done'],\n",
    "                    record['fields']['last_epic_num'],\n",
    "                    json.dumps(record['fields']['configuration']),\n",
    "                    record['fields']['workspace_type'],\n",
    "                    datetime.strptime(record['fields']['created_at'], \"%Y-%m-%d %H:%M:%S %Z\"),\n",
    "                    datetime.strptime(record['fields']['updated_at'], \"%Y-%m-%d %H:%M:%S %Z\"),\n",
    "                    record['links'].get('parent_id'),\n",
    "                    record['links'].get('scoring_system_id'),\n",
    "                    record['links']['idea_workflow_id'],\n",
    "                    record['links']['feature_workflow_id'],\n",
    "                    record['links']['release_workflow_id'],\n",
    "                ))\n",
    "\n",
    "                if len(project) % 10 == 0:\n",
    "                    tmp_df = pd.DataFrame(project, columns=[f.name for f in project_schema])\n",
    "                    w.write_table(pa.Table.from_pandas(tmp_df, schema=project_schema))\n",
    "                    project = []\n",
    "                    \n",
    "            elif record['class'] == 'Requirement':\n",
    "                i += 1\n",
    "                requirement.append((\n",
    "                    record['id'],\n",
    "                    record['fields']['reference_num'],\n",
    "                    str(record['fields']['created_by_user_id']),\n",
    "                    record['fields']['position'],\n",
    "                    float(record['fields']['original_estimate'])\n",
    "                        if record['fields']['original_estimate'] else None,\n",
    "                    float(record['fields']['remaining_estimate'])\n",
    "                        if record['fields']['remaining_estimate'] else None,\n",
    "                    float(record['fields']['work_done']) \n",
    "                        if record['fields']['work_done'] else None,\n",
    "                    record['fields']['name'],\n",
    "                    datetime.strptime(record['fields']['created_at'], \"%Y-%m-%d %H:%M:%S %Z\"),\n",
    "                    datetime.strptime(record['fields']['updated_at'], \"%Y-%m-%d %H:%M:%S %Z\"),\n",
    "                    record['links']['feature_id'],\n",
    "                    record['links']['project_id'],\n",
    "                    record['links']['workflow_status_id'],\n",
    "                    record['links'].get('assigned_to_user_id'),\n",
    "                ))\n",
    "\n",
    "                if len(requirement) % 1000 == 0:\n",
    "                    tmp_df = pd.DataFrame(requirement, columns=[f.name for f in requirement_schema])\n",
    "                    r.write_table(pa.Table.from_pandas(tmp_df, schema=requirement_schema))\n",
    "                    requirement = []\n",
    "\n",
    "                \n",
    "print(f\"{i} records found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read parquet data file into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_parquet(requirement_pq)\n",
    "output_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
