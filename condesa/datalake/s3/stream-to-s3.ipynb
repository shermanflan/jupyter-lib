{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ccc738",
   "metadata": {},
   "source": [
    "# Upload S3 Content as a Stream\n",
    "\n",
    "References:\n",
    "- [Overview](https://aws.amazon.com/blogs/storage/querying-data-without-servers-or-databases-using-amazon-s3-select)\n",
    "- [User Guide](https://docs.aws.amazon.com/AmazonS3/latest/userguide/selecting-content-from-objects.html)\n",
    "- [Client.select_object_content](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.select_object_content)\n",
    "\n",
    "To Do:\n",
    "- Consider [Smart Open](https://github.com/RaRe-Technologies/smart_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375572c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import closing\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "import gzip as gz\n",
    "import logging\n",
    "from os import environ\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError, EventStreamError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb61b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s',\n",
    "                    datefmt='%I:%M:%S %p', level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113411f",
   "metadata": {},
   "source": [
    "# Stream S3\n",
    "Use `Body` attribute and `iter_lines()`.\n",
    "\n",
    "References:\n",
    "- [StreamingBody](https://botocore.amazonaws.com/v1/documentation/api/latest/reference/response.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2030a",
   "metadata": {},
   "source": [
    "## List Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "s3_client = boto3.client('s3',\n",
    "        aws_access_key_id=environ['P3_AWS_ACCESS_KEY_ID'],\n",
    "        aws_secret_access_key=environ['P3_AWS_SECRET_ACCESS_KEY'],\n",
    "        aws_session_token=environ['P3_AWS_SESSION_TOKEN']\n",
    ")\n",
    "\n",
    "exports = s3_client.list_objects_v2(\n",
    "            Bucket='my-bucket',\n",
    "            Prefix='org/unload'\n",
    "        )\n",
    "\n",
    "for part in exports.get('Contents', []):\n",
    "\n",
    "    logger.info(f\"lake_path is {part['Key']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abefa58",
   "metadata": {},
   "source": [
    "## Download / Upload S3 Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add21cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "s3_hj_client = boto3.client('s3')\n",
    "s3_client = boto3.client('s3',\n",
    "        aws_access_key_id=environ['P3_AWS_ACCESS_KEY_ID'],\n",
    "        aws_secret_access_key=environ['P3_AWS_SECRET_ACCESS_KEY'],\n",
    "        aws_session_token=environ['P3_AWS_SESSION_TOKEN']\n",
    ")\n",
    "prefix = 'test-file' \n",
    "\n",
    "allergy_obj = s3_hj_client.get_object(\n",
    "    Bucket='my-bucket',\n",
    "    Key=f'org/unload/{prefix}'\n",
    ")\n",
    "\n",
    "with closing(allergy_obj['Body']) as body: \n",
    "\n",
    "    s3_client.upload_fileobj(\n",
    "        Fileobj=body,\n",
    "        Bucket='my-bucket2',\n",
    "        Key=f'org/upload/{prefix}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bed56",
   "metadata": {},
   "source": [
    "## Stream GZip to S3\n",
    "`StreamingBody` has no `seek()` method so it is not able to be part of a stream chain with `gzip.GzipFile`.\n",
    "\n",
    "References:\n",
    "- https://kokes.github.io/blog/2018/07/26/s3-objects-streaming-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce27692",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import codecs\n",
    "\n",
    "s3_hj_client = boto3.client('s3')\n",
    "s3_client = boto3.client('s3',\n",
    "        aws_access_key_id='',\n",
    "        aws_secret_access_key='',\n",
    ")\n",
    "\n",
    "allergy_obj = s3_hj_client.get_object(\n",
    "    Bucket='my-bucket',\n",
    "    Key='org/unload/test-file'\n",
    ")\n",
    "\n",
    "body = allergy_obj['Body'] # botocore.response.StreamingBody\n",
    "\n",
    "with closing(body):\n",
    "    with gz.open(body, 'rb') as unzipped:\n",
    "\n",
    "        s3_client.upload_fileobj(\n",
    "            Fileobj=BytesIO(unzipped.read()), # this works but is not streaming\n",
    "#             Fileobj=unzipped,  # fails, missing seek\n",
    "            Bucket='my-bucket2',\n",
    "            Key='org/unload/test-file',\n",
    "        )\n",
    "\n",
    "logger.info(f\"Result is complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d49f1",
   "metadata": {},
   "source": [
    "## Iterator Implementation\n",
    "Adapting the `EventStream` class to a true \"file-like object\" is difficult as it is an iterator and not a stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51aea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3SelectContentIterator:\n",
    "\n",
    "    def __init__(self, raw_stream, chunk_size=1024):\n",
    "        self._raw_stream = raw_stream # botocore.eventstream.EventStream\n",
    "        self._chunk_size = chunk_size\n",
    "        self._amount_read = 0\n",
    "        self.end_event_received = False\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Read at most amt bytes from the stream.\n",
    "        If the amt argument is omitted, read all data.\n",
    "        \"\"\"\n",
    "        event_stream = self._raw_stream # botocore.eventstream.EventStream\n",
    "        self.end_event_received = False\n",
    "        chunk = b''\n",
    "\n",
    "        # Iterate over events in the event stream\n",
    "        for event in event_stream:\n",
    "            \n",
    "            # Received a records event\n",
    "            if 'Records' in event:\n",
    "                data = event['Records']['Payload']\n",
    "                chunk = chunk + data\n",
    "\n",
    "            # End event indicates that the request finished successfully\n",
    "            elif 'End' in event:\n",
    "                self.end_event_received = True\n",
    "\n",
    "            if len(chunk) >= self._chunk_size:\n",
    "                self._amount_read += len(chunk)\n",
    "                logger.info(f\"data chunk: {self._amount_read}\")\n",
    "                yield chunk\n",
    "                chunk = b''\n",
    "\n",
    "        if not self.end_event_received:\n",
    "            logger.info(\"End event not received, request incomplete.\")\n",
    "                \n",
    "        if len(chunk) > 0:\n",
    "            self._amount_read += len(chunk)\n",
    "            logger.info(f\"last data chunk: {self._amount_read}\")\n",
    "            yield chunk\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the underlying event stream.\"\"\"\n",
    "        self._raw_stream.close()\n",
    "\n",
    "s3_hj_client = boto3.client('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "        \n",
    "content = s3_client.select_object_content(\n",
    "    Bucket='my-bucket',\n",
    "    Key=\"test-file.csv\",\n",
    "    RequestProgress = {\n",
    "        'Enabled': False\n",
    "    },\n",
    "    ExpressionType=\"SQL\",\n",
    "    Expression=\"\"\"\n",
    "        SELECT  *\n",
    "        FROM    s3object AS s3\n",
    "        --LIMIT 20\n",
    "    \"\"\",\n",
    "    InputSerialization = {\"CSV\": {'FileHeaderInfo': 'USE'}},\n",
    "    OutputSerialization = {\"CSV\": {}},\n",
    ")\n",
    "\n",
    "event_stream = content['Payload'] # botocore.eventstream.EventStream\n",
    "stream_adapter = S3SelectContentIterator(event_stream, 10024)\n",
    "\n",
    "with closing(stream_adapter): \n",
    "    for data in stream_adapter:\n",
    "        records = data.decode('utf-8')\n",
    "\n",
    "logger.info(\"Result is complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
